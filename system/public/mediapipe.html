<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Mediapipe Hands Bare Bones Example</title>
  </head>

  <body>
    <style>
      body {
        margin: 0;
      }
      video,
      canvas {
        position: absolute;
        left: 0px;
        top: 0px;
      }
      video {
        background: rgba(255, 0, 0, 0.5);
        opacity: 0;
      }
      #buffer {
        background: yellow;
      }
    </style>

    <script
      src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"
      crossorigin="anonymous"
    ></script>

    <script
      src="aesthetic.computer/dep/@mediapipe/hands/hands.js"
      crossorigin="anonymous"
    ></script>

    <video id="cam" autoplay playsinline></video>
    <canvas id="hand"></canvas>

    <script type="module">
      import {
        HandLandmarker,
        FilesetResolver,
      } from "https://cdn.skypack.dev/@mediapipe/tasks-vision@0.1.0-alpha-11";

      let handLandmarker = undefined;
      let processing = true;

      const createHandLandmarker = async () => {
        const vision = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.1.0-alpha-11/wasm"
        );
        handLandmarker = await HandLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-assets/hand_landmarker.task`,
          },
          runningMode: "VIDEO",
          numHands: 2,
        });
      };
      await createHandLandmarker(); // Preload hand model data

      // Read frames from video and draw data to canvas.

      const video = document.getElementById("cam");
      const canvas = document.getElementById("hand");
      const ctx = canvas.getContext("2d");

      const buffer = document.createElement("canvas");
      buffer.id = "buffer";

      const bufferCtx = buffer.getContext("2d");

      // Set the resolution of an intermediate buffer to paste
      // video data on and then read for hand data.

      // Actual resolution.
      buffer.width = window.innerWidth / 4;
      buffer.height = window.innerHeight / 4;

      canvas.width = buffer.width;
      canvas.height = buffer.height;

      // Display resolution.
      buffer.style.width = window.innerWidth + "px";
      buffer.style.height = window.innerHeight + "px";

      canvas.style.width = video.style.width = buffer.style.width;
      canvas.style.height = video.style.height = buffer.style.height;

      buffer.style.width = canvas.style.width;
      buffer.style.height = canvas.style.height;

      document.body.prepend(buffer); // Add buffer to dom.

      // Activate the webcam stream.
      navigator.mediaDevices
        .getUserMedia({
          video: {
            width: { ideal: window.innerWidth / 4 },
            height: { ideal: window.innerHeight / 4 },
            frameRate: { ideal: 60 },
            aspectRatio: {ideal: 1.7}
          },
        })
        .then((stream) => {
          video.srcObject = stream;
          video.addEventListener("loadeddata", process);
        });

      function process() {
        console.log("w:", video.videoWidth, "h:", video.videoHeight);
        const videoAR = video.videoWidth / video.videoHeight;
        const bufferAR = buffer.width / buffer.height;

        let outWidth;
        let outHeight;
        let outX = 0;
        let outY = 0;

        // alert(`video w: ${video.videoWidth} h: ${video.videoHeight} r: ${videoAR}`);
        // alert(`buffer w: ${buffer.width} h: ${buffer.height} r: ${bufferAR}`);

        if (videoAR <= bufferAR) {
          outWidth = buffer.width;
          outHeight = outWidth / videoAR;
          outY = ((buffer.height - outHeight) / 2) ;
        } else {
          outHeight = buffer.height;
          outWidth = outHeight * videoAR;
          outX = ((buffer.width - outWidth) / 2) ;
        }

        bufferCtx.drawImage(video, outX, outY, outWidth, outHeight);

        // Read hand data from buffer.
        const results = handLandmarker.detectForVideo(
          buffer,
          performance.now()
        );

        // Render...
        ctx.save();
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        if (results.landmarks) {
          for (const landmarks of results.landmarks) {
            drawConnectors(ctx, landmarks, HAND_CONNECTIONS, {
              color: "#00FF00",
              lineWidth: 5,
            });
            drawLandmarks(ctx, landmarks, {
              color: "#FF0000",
              lineWidth: 2,
            });
          }
        }
        ctx.restore();

        // TODO: Send the data to aesthetic.computer disk for rendering.
        if (processing === true) window.requestAnimationFrame(process);
      }
    </script>
  </body>
</html>
